# LangGraph RAG Assistant Configuration

# LLM Settings
llm:
  model: "gpt-4-turbo-preview"
  temperature: 0.7
  max_tokens: 1024
  streaming: true

# Embedding Settings
embeddings:
  model: "text-embedding-ada-002"
  batch_size: 100

# Vector Store Settings
vector_store:
  provider: "chroma"
  collection_name: "documents"
  persist_directory: "./data/chroma"
  distance_metric: "cosine"

# Chunking Settings
chunking:
  chunk_size: 1000
  chunk_overlap: 200
  separators:
    - "\n\n"
    - "\n"
    - ". "
    - " "

# Retrieval Settings
retrieval:
  top_k: 5
  score_threshold: 0.7
  rerank: false
  hybrid_search: false
  keyword_weight: 0.3
  semantic_weight: 0.7

# Conversation Settings
conversation:
  max_history_turns: 10
  context_window: 4096

# Quality Thresholds
quality:
  min_relevance_score: 0.5
  min_confidence_score: 0.6
  max_sources: 5

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
